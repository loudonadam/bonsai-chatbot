2025-12-27 22:08:34	llama-server exited immediately with code unknown. Check C:\Users\loudo\Desktop\bonsai-chatbot\bonsai-chatbot\logs\llama-server-stderr.log.
No stderr output was captured. Confirm the binary exists, the model path is correct, and try running the command manually from the repo root:

  "scripts\\llama-server.exe" --model models\\bonsai-gguf.gguf --host 127.0.0.1 --port 8080 --ctx-size 4096 --n-gpu-layers 35 --embedding
Retry exit code: -1073741515
If you still see no output, Windows may be blocking the binary (right-click > Properties > Unblock) or the VC++ runtime/GPU DLLs may be missing.
2025-12-28 01:33:30	llama-server self-test (--version) failed. Exit code: -1. Output:
ggml_vulkan: Found 2 Vulkan devices:
Exit code -1073741515 (0xC0000135) usually means a missing DLL or blocked binary. Ensure ggml*.dll, llama.dll, mtmd.dll sit next to llama-server.exe, and right-click > Properties > Unblock. If you built llama.cpp yourself, copy everything from build\\bin\\Release next to the exe.
2025-12-28 01:40:39	llama-server self-test (--version) failed. Exit code: -1. Output:
ggml_vulkan: Found 2 Vulkan devices:
Exit code -1073741515 (0xC0000135) usually means a missing DLL or blocked binary. Ensure ggml*.dll, llama.dll, mtmd.dll sit next to llama-server.exe, and right-click > Properties > Unblock. If you built llama.cpp yourself, copy everything from build\\bin\\Release next to the exe.
2025-12-28 01:40:57	llama-server self-test (--version) failed. Exit code: -1. Output:
ggml_vulkan: Found 2 Vulkan devices:
Exit code -1073741515 (0xC0000135) usually means a missing DLL or blocked binary. Ensure ggml*.dll, llama.dll, mtmd.dll sit next to llama-server.exe, and right-click > Properties > Unblock. If you built llama.cpp yourself, copy everything from build\\bin\\Release next to the exe.
2025-12-28 01:44:16	llama-server self-test (--version) failed. Exit code: -1. Output:
ggml_vulkan: Found 2 Vulkan devices:
Exit code -1073741515 (0xC0000135) usually means a missing DLL or blocked binary. Ensure ggml*.dll, llama.dll, mtmd.dll sit next to llama-server.exe, and right-click > Properties > Unblock. If you built llama.cpp yourself, copy everything from build\\bin\\Release next to the exe.
<<<<<<< Updated upstream
=======
2025-12-28 01:46:02	llama-server self-test (--version) failed. Exit code: -1. Output:
ggml_vulkan: Found 2 Vulkan devices:
Exit code -1073741515 (0xC0000135) usually means a missing DLL or blocked binary. Ensure ggml*.dll, llama.dll, mtmd.dll sit next to llama-server.exe, and right-click > Properties > Unblock. If you built llama.cpp yourself, copy everything from build\\bin\\Release next to the exe.
>>>>>>> Stashed changes
2025-12-28 01:49:08	llama-server self-test (--version) failed. Exit code: -1. Output:
ggml_vulkan: Found 2 Vulkan devices:
Exit code -1073741515 (0xC0000135) usually means a missing DLL or blocked binary. Ensure ggml*.dll, llama.dll, mtmd.dll sit next to llama-server.exe, and right-click > Properties > Unblock. If you built llama.cpp yourself, copy everything from build\\bin\\Release next to the exe.
2025-12-28 01:50:59	llama-server self-test (--version) failed. Exit code: -1. Output:
ggml_vulkan: Found 2 Vulkan devices:
Exit code -1073741515 (0xC0000135) usually means a missing DLL or blocked binary. Ensure ggml*.dll, llama.dll, mtmd.dll sit next to llama-server.exe, and right-click > Properties > Unblock. If you built llama.cpp yourself, copy everything from build\\bin\\Release next to the exe.
2025-12-28 01:53:39	llama-server self-test (--version) failed. Exit code: -1. Output:
ggml_vulkan: Found 2 Vulkan devices:
Exit code -1073741515 (0xC0000135) usually means a missing DLL or blocked binary. Ensure ggml*.dll, llama.dll, mtmd.dll sit next to llama-server.exe, and right-click > Properties > Unblock. If you built llama.cpp yourself, copy everything from build\\bin\\Release next to the exe.
Hint: multiple Vulkan devices detected. Try setting -VulkanDevice <index> (0-based) or VK_ICD_FILENAMES to point at the discrete GPU ICD.
>>>>>>> Stashed changes
